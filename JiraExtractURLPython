import requests
import pandas as pd
from requests.auth import HTTPBasicAuth

# Your Jira details
JIRA_URL = 'https://your-domain.atlassian.net'
JQL = 'your JQL query here'
EMAIL = 'your-email@domain.com'
API_TOKEN = 'your_api_token'

auth = HTTPBasicAuth(EMAIL, API_TOKEN)
headers = {
    "Accept": "application/json"
}

url = f"{JIRA_URL}/rest/api/3/search?jql={JQL}&fields=key,summary,customfield_X,currentVersions,customfield_Y,customfield_Z"

response = requests.request(
    "GET",
    url,
    headers=headers,
    auth=auth
)

if response.status_code == 200:
    data = response.json()
    issues = data['issues']
    
    columns = ['Key', 'Summary', 'Current Versions', 'Effort ID', 'Type of Work']
    rows = []

    for issue in issues:
        key = issue['key']
        summary = issue['fields']['summary']
        # Replace 'customfield_X' with the actual field ID for "Current Versions"
        current_versions = issue['fields'].get('customfield_X', 'N/A')  
        # Replace 'customfield_Y' with the actual field ID for "Effort ID"
        effort_id = issue['fields'].get('customfield_Y', 'N/A')
        # Replace 'customfield_Z' with the actual field ID for "Type of Work"
        type_of_work = issue['fields'].get('customfield_Z', 'N/A')
        
        rows.append([key, summary, current_versions, effort_id, type_of_work])

    df = pd.DataFrame(rows, columns=columns)
    
    excel_file_path = 'jira_issues.xlsx'
    df.to_excel(excel_file_path, index=False)
    print(f"Data saved to {excel_file_path}")
else:
    print("Failed to fetch data:", response.text)







# korn shell script in Linux
#!/bin/bash

# Array of Documentum file URLs
urls=(
  "https://documentum.example.com/file1"
  "https://documentum.example.com/file2"
)

# Directory where files will be saved
save_dir="/mnt/shared_drive/documents"

# Ensure the save directory exists
mkdir -p "$save_dir"

# Loop through URLs and download each file
for url in "${urls[@]}"; do
  wget -P "$save_dir" "$url"
done






# Powershell .ps1 script

# Array of Documentum file URLs
$urls = @(
    "https://documentum.example.com/file1",
    "https://documentum.example.com/file2"
)

# Directory where files will be saved
$saveDir = "Z:\shared_drive\documents" # Adjust the path as needed

# Ensure the save directory exists
if (-not (Test-Path -Path $saveDir)) {
    New-Item -ItemType Directory -Path $saveDir
}

# Loop through URLs and download each file
foreach ($url in $urls) {
    $fileName = [System.IO.Path]::GetFileName($url)
    $destinationPath = Join-Path -Path $saveDir -ChildPath $fileName
    Invoke-WebRequest -Uri $url -OutFile $destinationPath
}








# Python script

import os
import requests

# List of Documentum file URLs
urls = [
    "https://documentum.example.com/file1",
    "https://documentum.example.com/file2",
]

# Directory where files will be saved
save_dir = "/mnt/shared_drive/documents"  # Adjust for Windows or Linux path

# Ensure the save directory exists
os.makedirs(save_dir, exist_ok=True)

# Download each file
for url in urls:
    response = requests.get(url)
    filename = os.path.join(save_dir, url.split('/')[-1])

    with open(filename, 'wb') as f:
        f.write(response.content)

