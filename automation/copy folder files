
import requests
from bs4 import BeautifulSoup

url = 'http://example.com/main'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
file_links = []

for a in soup.find_all('a', href=True):
    if 'pfmt=' in a['href']:
        file_links.append(a['href'])

with open('urls.txt', 'w') as f:
    for link in file_links:
        f.write(f"{link}\n")




import requests
from bs4 import BeautifulSoup

# URL of the page where files are listed
url = 'http://example.com/documentum/folder/'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# Assuming files are in <a> tags and directly downloadable
for link in soup.find_all('a'):
    file_url = link.get('href')
    if file_url:
        print("Downloading:", file_url)
        r = requests.get(file_url)
        with open(file_url.split('/')[-1], 'wb') as f:
            f.write(r.content)
