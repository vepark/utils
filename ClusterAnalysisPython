import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import nltk

# Download NLTK data (run this once)
# nltk.download('stopwords')
# nltk.download('wordnet')

# Load the Excel file
df = pd.read_excel('path_to_your_file.xlsx')

# Pre-process the text
def preprocess_text(text):
    text = text.lower()
    lemmatizer = WordNetLemmatizer()
    words = nltk.word_tokenize(text)
    words = [lemmatizer.lemmatize(word) for word in words if word.isalpha()]
    return ' '.join(words)

df['processed_findings'] = df['findings_column'].apply(preprocess_text)

# Vectorize the text
vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))
X = vectorizer.fit_transform(df['processed_findings'])

# Cluster the data
n_clusters = 5  # Adjust this based on your data
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
df['cluster'] = kmeans.fit_predict(X)

# Analyze the clusters
for i in range(n_clusters):
    print(f"\nCluster {i}:")
    print(df[df['cluster'] == i]['findings_column'])

# Save the result to a new Excel file
df.to_excel('clustered_findings.xlsx', index=False)
